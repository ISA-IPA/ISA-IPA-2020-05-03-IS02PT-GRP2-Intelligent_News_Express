{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyteaser import Summarize, SummarizeUrl\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tagui as t\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB Connection setup\n"
     ]
    }
   ],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(\"DB Connection setup\")\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            return conn\n",
    "        else:\n",
    "            print(\"DB Connection failed\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conn = create_connection(\"./db/news.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSiteByName(name):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM site where name=?\",(name,))\n",
    "    rows = cur.fetchall()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = getSiteByName(\"StraitsTimes\")\n",
    "url = site[0][2]\n",
    "site_id = site[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.init(visual_automation = True, chrome_browser = True)\n",
    "t.url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\superhell\\.conda\\envs\\ca1\\lib\\site-packages\\BeautifulSoup.py:114: UserWarning: You are using a very old release of Beautiful Soup, last updated in 2011. If you installed the 'beautifulsoup' package through pip, you should know the 'beautifulsoup' package name is about to be reclaimed by a more recent version of Beautiful Soup which is incompatible with this version.\n",
      "\n",
      "This will happen at some point after January 1, 2021.\n",
      "\n",
      "If you just started this project, this is easy to fix. Install the 'beautifulsoup4' package instead of 'beautifulsoup' and start using Beautiful Soup 4.\n",
      "\n",
      "If this is an existing project that depends on Beautiful Soup 3, the project maintainer (potentially you) needs to start the process of migrating to Beautiful Soup 4. This should be a relatively easy part of the Python 3 migration.\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RPA][ERROR] - cannot find //div[contains(@data-vr-zone, \"Top Stories 8\")]//span[contains(@class, \"story-headline\")]/ancestor::div[contains(@class, \"body\")]/..//img/@src\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_bb = t.count('(//div[contains(@data-vr-zone, \"Top Stories\")]//span[contains(@class, \"story-headline\")])')\n",
    "\n",
    "df_bb = pd.DataFrame(index=range(0,number_bb-2), columns = ['Sno', 'Title', 'URL', 'Summary','Img_URL'])\n",
    "\n",
    "\n",
    "for n in range(0, number_bb-2):\n",
    "    title=t.read('//div[contains(@data-vr-zone, \"Top Stories {}\")]//span[contains(@class, \"story-headline\")]'.format(n))\n",
    "    URL_b=t.read('//div[contains(@data-vr-zone, \"Top Stories {}\")]//span[contains(@class, \"story-headline\")]//@href'.format(n))\n",
    "    URL = \"https://www.straitstimes.com/\" + str(URL_b)\n",
    "    Img_URL = t.read('//div[contains(@data-vr-zone, \"Top Stories {}\")]//span[contains(@class, \"story-headline\")]/ancestor::div[contains(@class, \"body\")]/..//img/@src'.format(n))\n",
    "    summaries = SummarizeUrl(URL)\n",
    "    \n",
    "    df_bb.iloc[n, 0] = n\n",
    "    df_bb.iloc[n, 1] = title\n",
    "    df_bb.iloc[n, 2] = URL\n",
    "    df_bb.iloc[n, 3] = summaries\n",
    "    df_bb.iloc[n, 4] = Img_URL\n",
    "    \n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertNews(conn,news):    \n",
    "    sql = ''' INSERT INTO news(site_id,create_date,title,url,summary,img_url,latest)\n",
    "              VALUES(?,?,?,?,?,?,1) '''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, news)\n",
    "    return cur.lastrowid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markNews(conn, site_id):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"UPDATE news set latest=0 where latest=1 and site_id=? \",(site_id,))\n",
    "    print(\"News has been marked as old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News has been marked as old\n",
      "News 10 has been created\n",
      "News 11 has been created\n",
      "News 12 has been created\n",
      "News 13 has been created\n",
      "News 14 has been created\n",
      "News 15 has been created\n",
      "News 16 has been created\n",
      "News 17 has been created\n",
      "News 18 has been created\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "# dd/mm/YY\n",
    "dt_string = now.strftime(\"%d/%m/%Y\")\n",
    "markNews(conn, site_id)\n",
    "for index, row in df_bb.iterrows():\n",
    "    title = row['Title']\n",
    "    url = row['URL']\n",
    "    summary = str(row['Summary'])\n",
    "    img_url = row['Img_URL']\n",
    "    news = (site_id,dt_string,title,url,summary,img_url)\n",
    "    news_id = insertNews(conn,news)\n",
    "    print(\"News %d has been created\" % news_id)\n",
    "    \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
